{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 410 Final Project: Generating Summaries for News Articles\n",
    "Aaron Kuhstoss, Shalin Mehta, and Aleksandra Grigortsuk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import random \n",
    "\n",
    "import torch\n",
    "import rouge\n",
    "from rouge import Rouge\n",
    "from bert_score import score\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Data Preprocessing\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86560\n"
     ]
    }
   ],
   "source": [
    "# import the dataset\n",
    "df = pd.read_csv(\"Latest_News.csv\")\n",
    "print(len(df))\n",
    "\n",
    "# filtering dataset with English articles and non-NA \n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Subset df to make it workable, since python is computationally slow\n",
    "#random.seed(410)\n",
    "#df_subset = df.sample(n=15000)\n",
    "\n",
    "# For my purposes I'll take a subset of the same 15000 for consistency\n",
    "df_subset = df.sample(n=15000,random_state=410) # random_state should stay consistent each time as long as we use the same csv file\n",
    "\n",
    "# Apply the language detection function to df\n",
    "df_subset['detected_language'] = df_subset['content'].apply(detect_language)\n",
    "english_articles = df_subset[df_subset['detected_language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153\n",
      "2247.8187337380746\n",
      "222.00648148148147\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>keywords</th>\n",
       "      <th>creator</th>\n",
       "      <th>video_url</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>full_description</th>\n",
       "      <th>image_url</th>\n",
       "      <th>source_id</th>\n",
       "      <th>detected_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57562</th>\n",
       "      <td>Succession Recap: Relevant Donuts</td>\n",
       "      <td>http://www.vulture.com/article/succession-seas...</td>\n",
       "      <td>['tv', 'tv recaps', 'overnights', 'recaps', 's...</td>\n",
       "      <td>['Scott Tobias']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Roy children consider taking “a pop at the...</td>\n",
       "      <td>In “Austerlitz,” the seventh episode of Succes...</td>\n",
       "      <td>2021-10-25 02:02:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vulture</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64707</th>\n",
       "      <td>Giants stifle Panthers in impressive win</td>\n",
       "      <td>https://nationalpost.com/pmn/sports-pmn/giants...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Reuters']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Daniel Jones threw a touchdown pass and the Ne...</td>\n",
       "      <td>Daniel Jones threw a touchdown pass and the Ne...</td>\n",
       "      <td>2021-10-24 20:21:11</td>\n",
       "      <td>Daniel Jones threw a touchdown pass and the Ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nationalpost</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22871</th>\n",
       "      <td>The original iPod ‘prototype’ was an Apple des...</td>\n",
       "      <td>https://www.theverge.com/2021/10/25/22744761/a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Emma Roth']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Photo by Panic It’s hard to believe that the p...</td>\n",
       "      <td>2021-10-25 16:53:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>theverge</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75223</th>\n",
       "      <td>3 Best Ways to Invest for Retirement</td>\n",
       "      <td>https://www.fool.com/retirement/2021/10/24/3-b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['newsfeedback@fool.com (Chuck Saletta)']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Taking advantage of these specialized retireme...</td>\n",
       "      <td>Covering your costs in your retirement will pr...</td>\n",
       "      <td>2021-10-24 14:30:00</td>\n",
       "      <td>Covering your costs in your retirement will pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fool</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62191</th>\n",
       "      <td>Verstappen gamble sets up thrilling US GP finale</td>\n",
       "      <td>https://wwos.nine.com.au/motorsport/f1-2021-ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['wwos']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Max Verstappen stopped early for tyres, settin...</td>\n",
       "      <td>Max Verstappen held off Formula One title riva...</td>\n",
       "      <td>2021-10-24 21:50:15</td>\n",
       "      <td>Max Verstappen held off Formula One title riva...</td>\n",
       "      <td>https://vms-network-images-prod.s3-ap-southeas...</td>\n",
       "      <td>nine</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "57562                  Succession Recap: Relevant Donuts   \n",
       "64707           Giants stifle Panthers in impressive win   \n",
       "22871  The original iPod ‘prototype’ was an Apple des...   \n",
       "75223               3 Best Ways to Invest for Retirement   \n",
       "62191   Verstappen gamble sets up thrilling US GP finale   \n",
       "\n",
       "                                                    link  \\\n",
       "57562  http://www.vulture.com/article/succession-seas...   \n",
       "64707  https://nationalpost.com/pmn/sports-pmn/giants...   \n",
       "22871  https://www.theverge.com/2021/10/25/22744761/a...   \n",
       "75223  https://www.fool.com/retirement/2021/10/24/3-b...   \n",
       "62191  https://wwos.nine.com.au/motorsport/f1-2021-ma...   \n",
       "\n",
       "                                                keywords  \\\n",
       "57562  ['tv', 'tv recaps', 'overnights', 'recaps', 's...   \n",
       "64707                                                NaN   \n",
       "22871                                                NaN   \n",
       "75223                                                NaN   \n",
       "62191                                                NaN   \n",
       "\n",
       "                                         creator video_url  \\\n",
       "57562                           ['Scott Tobias']       NaN   \n",
       "64707                                ['Reuters']       NaN   \n",
       "22871                              ['Emma Roth']       NaN   \n",
       "75223  ['newsfeedback@fool.com (Chuck Saletta)']       NaN   \n",
       "62191                                   ['wwos']       NaN   \n",
       "\n",
       "                                             description  \\\n",
       "57562  The Roy children consider taking “a pop at the...   \n",
       "64707  Daniel Jones threw a touchdown pass and the Ne...   \n",
       "22871                                                NaN   \n",
       "75223  Taking advantage of these specialized retireme...   \n",
       "62191  Max Verstappen stopped early for tyres, settin...   \n",
       "\n",
       "                                                 content              pubDate  \\\n",
       "57562  In “Austerlitz,” the seventh episode of Succes...  2021-10-25 02:02:09   \n",
       "64707  Daniel Jones threw a touchdown pass and the Ne...  2021-10-24 20:21:11   \n",
       "22871  Photo by Panic It’s hard to believe that the p...  2021-10-25 16:53:42   \n",
       "75223  Covering your costs in your retirement will pr...  2021-10-24 14:30:00   \n",
       "62191  Max Verstappen held off Formula One title riva...  2021-10-24 21:50:15   \n",
       "\n",
       "                                        full_description  \\\n",
       "57562                                                NaN   \n",
       "64707  Daniel Jones threw a touchdown pass and the Ne...   \n",
       "22871                                                NaN   \n",
       "75223  Covering your costs in your retirement will pr...   \n",
       "62191  Max Verstappen held off Formula One title riva...   \n",
       "\n",
       "                                               image_url     source_id  \\\n",
       "57562                                                NaN       vulture   \n",
       "64707                                                NaN  nationalpost   \n",
       "22871                                                NaN      theverge   \n",
       "75223                                                NaN          fool   \n",
       "62191  https://vms-network-images-prod.s3-ap-southeas...          nine   \n",
       "\n",
       "      detected_language  \n",
       "57562                en  \n",
       "64707                en  \n",
       "22871                en  \n",
       "75223                en  \n",
       "62191                en  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(english_articles))\n",
    "print(english_articles['content'].str.len().mean())\n",
    "print(english_articles['description'].str.len().mean())\n",
    "\n",
    "print(english_articles['content'].isnull().sum())\n",
    "print(english_articles['title'].isnull().sum())\n",
    "\n",
    "# every article has content and title\n",
    "# 1157 articles\n",
    "# averege size of content is 2100 characters\n",
    "\n",
    "(english_articles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Construction\n",
    "1. Summarization pipeline\n",
    "2. Categorization pipline (optional) -- not possible without preassigned labels\n",
    "*does not need to be fully implemented by 11/1 milestone*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, per):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc= nlp(text)\n",
    "    tokens=[token.text for token in doc]\n",
    "    word_frequencies={}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in list(STOP_WORDS):\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "    max_frequency=max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word]=word_frequencies[word]/max_frequency\n",
    "    sentence_tokens= [sent for sent in doc.sents]\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_scores.keys():                            \n",
    "                    sentence_scores[sent]=word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent]+=word_frequencies[word.text.lower()]\n",
    "    select_length=int(len(sentence_tokens)*per)\n",
    "    summary=nlargest(select_length, sentence_scores,key=sentence_scores.get)\n",
    "    final_summary=[word.text for word in summary]\n",
    "    summary=''.join(final_summary)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Summaries\n",
    "\n",
    "Takes about 10 minutes. May need to further reduce the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(summarize(english_articles.iloc[0,6], 0.1))\n",
    "#print(english_articles.iloc[0,6])\n",
    "\n",
    "summaries = []\n",
    "raw_articles = []\n",
    "#for i in range(len(english_articles)):\n",
    "#    summary = summarize(english_articles.iloc[i,6], 0.1)\n",
    "#    if summary:\n",
    "#        summaries.append(summary)\n",
    "\n",
    "# For the evaluation we don't need too many summaries, so I'll just do five for now\n",
    "index = 500\n",
    "while len(summaries) < 5:\n",
    "    article = english_articles.iloc[index,:]\n",
    "    article_content = english_articles.iloc[index,6]\n",
    "    summary = summarize(article_content, 0.1)\n",
    "    if summary:\n",
    "        summaries.append(summary)\n",
    "        raw_articles.append(article)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pic.twitter.com/QxoekDCB9H— Breaking Bad (@BreakingBad) February 11, 2020 RELATED: ‘Breaking Bad’: 5 Walter White Moments That Pushed Him Beyond Redemption Although most of the talking heads at AMC still saw Cranston as his fatherly persona from Malcolm in the Middle, Gilligan knew he had a wider acting range.Despite being a morally grey character — veering toward the darker side of the spectrum, if we’re being honest — Cranson’s character stuck with fans.These 2 actors could have played Walter White instead RELATED: ‘Breaking Bad’: Bryan Cranston Doesn’t Miss Playing Walter White for This Reason With Cranston becoming the face of Breaking Bad, it’s hard to imagine the show having another lead.',\n",
       " 'If you’ve been on TikTok in recent weeks, chances are that you’ve seen the term ‘weaponised incompetence’ (or weaponized) floating around a fair amount.Psychotherapist and writer, Emily Mendez, M.S. EdS, recently told Bustle that “Weaponized incompetence refers to pretending not to know how to do something when you do really know how to do it.”“What I can’t help but think about is how does weaponized incompetence impact the kids and the overall family dynamic?”',\n",
       " \"Petrol prices in Assam's Kamrup Metro district stood at ₹103.23 per litre on Sunday, up by ₹0.36 while diesel prices stood at ₹95.76, up by ₹0.37.\",\n",
       " 'Bieber’s 2021 album, Justice, is also vying for a nod as best pop vocal album, but the victory for Bieber is that his pop/soul jam “Peaches,” which could have gone either way, is competing in R&B — along with such other hits as Silk Sonic’s “Leave the Door Open” and SZA’s “Good Days.”Her other top 10 hits, “Déjà Vu,” “Good 4 U” and “Traitor,” are not listed.Ariana Grande, “Positions,” best pop solo performance (where it is vying for a nod with her “Still Hurting”).The Weeknd, whose “Blinding Lights” was infamously passed over for a nod last year, didn’t enter his 2021 hit “Take My Breath.”Live versions of such past hits as Adele’s “Set Fire to the Rain” and Pharrell Williams’ “Happy” have won Grammys, so a nod is a possibility.These include Lil Nas X’s “Montero (Call Me By Your Name)” and Lizzo featuring Cardi B’s “Rumors.”',\n",
       " 'Singer-songwriter Ed Sheeran on Sunday announced he had tested positive for COVID-19 and would be self-isolating in his home five days before he is scheduled to release his fourth studio album.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 1:\n",
      "  ROUGE-1:\n",
      "    R: 0.2857\n",
      "    P: 0.0870\n",
      "    F: 0.1333\n",
      "  ROUGE-2:\n",
      "    R: 0.0345\n",
      "    P: 0.0093\n",
      "    F: 0.0147\n",
      "  ROUGE-L:\n",
      "    R: 0.2143\n",
      "    P: 0.0652\n",
      "    F: 0.1000\n",
      "\n",
      "Summary 2:\n",
      "  ROUGE-1:\n",
      "    R: 0.4583\n",
      "    P: 0.3492\n",
      "    F: 0.3964\n",
      "  ROUGE-2:\n",
      "    R: 0.3019\n",
      "    P: 0.2192\n",
      "    F: 0.2540\n",
      "  ROUGE-L:\n",
      "    R: 0.4583\n",
      "    P: 0.3492\n",
      "    F: 0.3964\n",
      "\n",
      "Summary 3:\n",
      "  ROUGE-1:\n",
      "    R: 0.0000\n",
      "    P: 0.0000\n",
      "    F: 0.0000\n",
      "  ROUGE-2:\n",
      "    R: 0.0000\n",
      "    P: 0.0000\n",
      "    F: 0.0000\n",
      "  ROUGE-L:\n",
      "    R: 0.0000\n",
      "    P: 0.0000\n",
      "    F: 0.0000\n",
      "\n",
      "Summary 4:\n",
      "  ROUGE-1:\n",
      "    R: 0.4231\n",
      "    P: 0.0924\n",
      "    F: 0.1517\n",
      "  ROUGE-2:\n",
      "    R: 0.1481\n",
      "    P: 0.0280\n",
      "    F: 0.0471\n",
      "  ROUGE-L:\n",
      "    R: 0.4231\n",
      "    P: 0.0924\n",
      "    F: 0.1517\n",
      "\n",
      "Summary 5:\n",
      "  ROUGE-1:\n",
      "    R: 0.2778\n",
      "    P: 0.1724\n",
      "    F: 0.2128\n",
      "  ROUGE-2:\n",
      "    R: 0.0000\n",
      "    P: 0.0000\n",
      "    F: 0.0000\n",
      "  ROUGE-L:\n",
      "    R: 0.1667\n",
      "    P: 0.1034\n",
      "    F: 0.1277\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 1: Precision: 0.8928447961807251, Recall: 0.8430277109146118, F1: 0.8672213554382324\n",
      "Summary 2: Precision: 0.9354150295257568, Recall: 0.8361769914627075, F1: 0.8830165266990662\n",
      "Summary 3: Precision: 0.95087730884552, Recall: 0.8304088115692139, F1: 0.8865693807601929\n",
      "Summary 4: Precision: 0.8712972402572632, Recall: 0.7973340153694153, F1: 0.832676351070404\n",
      "Summary 5: Precision: 0.93096524477005, Recall: 0.8200744390487671, F1: 0.8720085620880127\n",
      "Summary 1:\n",
      "  ROUGE-1:\n",
      "    R: 0.4865\n",
      "    P: 0.1957\n",
      "    F: 0.2791\n",
      "  ROUGE-2:\n",
      "    R: 0.1026\n",
      "    P: 0.0374\n",
      "    F: 0.0548\n",
      "  ROUGE-L:\n",
      "    R: 0.3784\n",
      "    P: 0.1522\n",
      "    F: 0.2171\n",
      "\n",
      "Summary 2:\n",
      "  ROUGE-1:\n",
      "    R: 0.5273\n",
      "    P: 0.4603\n",
      "    F: 0.4915\n",
      "  ROUGE-2:\n",
      "    R: 0.3881\n",
      "    P: 0.3562\n",
      "    F: 0.3714\n",
      "  ROUGE-L:\n",
      "    R: 0.4909\n",
      "    P: 0.4286\n",
      "    F: 0.4576\n",
      "\n",
      "Summary 3:\n",
      "  ROUGE-1:\n",
      "    R: 0.0270\n",
      "    P: 0.0417\n",
      "    F: 0.0328\n",
      "  ROUGE-2:\n",
      "    R: 0.0000\n",
      "    P: 0.0000\n",
      "    F: 0.0000\n",
      "  ROUGE-L:\n",
      "    R: 0.0270\n",
      "    P: 0.0417\n",
      "    F: 0.0328\n",
      "\n",
      "Summary 4:\n",
      "  ROUGE-1:\n",
      "    R: 0.4222\n",
      "    P: 0.1597\n",
      "    F: 0.2317\n",
      "  ROUGE-2:\n",
      "    R: 0.1250\n",
      "    P: 0.0420\n",
      "    F: 0.0628\n",
      "  ROUGE-L:\n",
      "    R: 0.3778\n",
      "    P: 0.1429\n",
      "    F: 0.2073\n",
      "\n",
      "Summary 5:\n",
      "  ROUGE-1:\n",
      "    R: 0.7838\n",
      "    P: 1.0000\n",
      "    F: 0.8788\n",
      "  ROUGE-2:\n",
      "    R: 0.6500\n",
      "    P: 0.8667\n",
      "    F: 0.7429\n",
      "  ROUGE-L:\n",
      "    R: 0.7297\n",
      "    P: 0.9310\n",
      "    F: 0.8182\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 1: Precision: 0.8928447961807251, Recall: 0.8430277109146118, F1: 0.8672213554382324\n",
      "Summary 2: Precision: 0.9354150295257568, Recall: 0.8361769914627075, F1: 0.8830165266990662\n",
      "Summary 3: Precision: 0.95087730884552, Recall: 0.8304088115692139, F1: 0.8865693807601929\n",
      "Summary 4: Precision: 0.8712972402572632, Recall: 0.7973340153694153, F1: 0.832676351070404\n",
      "Summary 5: Precision: 0.93096524477005, Recall: 0.8200744390487671, F1: 0.8720085620880127\n"
     ]
    }
   ],
   "source": [
    "# Looking at summaries and their associated articles\n",
    "\n",
    "## NOTE: One fundamental issue we're dealing with is the fact that rouge and bleu need high qualtiy reference summaries to compare to,\n",
    "## if we use the \"description\" field as a pseudo summary, we can get a good amount of reference data, however the quality of these descriptions\n",
    "## varies, and some are null. We can also try writing summaries by hand to compare to, but this is time-consuming and limits us to fewer data points.\n",
    "\n",
    "# Obtain original descriptions for use as reference \"summaries\"\n",
    "descriptions = []\n",
    "\n",
    "for row in raw_articles:\n",
    "    descriptions.append(row.iloc[5])\n",
    "\n",
    "# Get raw content of articles for BERTscoring\n",
    "orig_articles = []\n",
    "for row in raw_articles:\n",
    "   orig_articles.append(row.iloc[6])\n",
    "\n",
    "# Display raw article content and descriptions\n",
    "#print('Raw Articles:','\\n'.join(orig_articles))\n",
    "#print('Descriptions:','\\n'.join(descriptions))\n",
    "\n",
    "# For sake of qualitative evaluation, display summaries\n",
    "#print('Summaries:','\\n'.join(summaries))\n",
    "\n",
    "# Also write hand-written summaries\n",
    "own_summ1 = \"Bryan Cranstons portrayal of the morally gray character Walter White in the hit series Breaking Bad has been loved by fans. However, AMC had other choices for the lead, with Breaking Bad creator Vince Gilligan ultimately persuading executives to choose Cranston.\"\n",
    "own_summ2 = \"Recently on TikTok, the term weaponized incompetence is gaining a lot of attention. According to psychotherapist and writer, Emily Mendez, M.S. EdS, “Weaponized incompetence refers to pretending not to know how to do something when you do really know how to do it.” The term has 21.8M views on TikTok as example, mostly of women, whose colleagues, partners, and family members use weaponized incompetence to get out of work.\"\n",
    "own_summ3 = \"The All India Congress is going to launch a country wide protest from November 14 against the abnormal rise of fuel. The massive protest against the high fuel price will start from November 14 and will continue till November 29, after five consecutive days of rising fuel prices across the country.\"\n",
    "own_summ4 = \"Numerous artists across multiple genres, such as Lil Nas X, Ariana Grande, and Olivia Rodrigo are entering songs for consideration in the upcoming Grammy award season. This includes Justin Bieber, whose smash hit “Peaches” (featuring Daniel Caesar and Giveon) is vying for a Grammy nomination as best R&B performance.\"\n",
    "own_summ5 = \"Singer-songwriter Ed Sheeran announced Sunday he had tested positive for COVID-19 and would be self-isolating in his home five days before he is scheduled to release his fourth studio album. Sheeran's upcoming album, titled '=' is scheduled to be released on October 29.\"\n",
    "\n",
    "own_summ = [own_summ1,own_summ2,own_summ3,own_summ4,own_summ5]\n",
    "\n",
    "# Return Rouge and BERTscores for all summaries passed in\n",
    "def eval_summaries(summaries,references,content):\n",
    "    # Initialize the ROUGE object\n",
    "    rouge = Rouge()\n",
    "\n",
    "    rouge_scores = [rouge.get_scores(summaries, references)]\n",
    "\n",
    "    for index, score_set in enumerate(rouge_scores[0]):\n",
    "        print(f\"Summary {index + 1}:\")\n",
    "        for rouge_key, values in score_set.items():\n",
    "            print(f\"  {rouge_key.upper()}:\")\n",
    "            for metric, value in values.items():\n",
    "                print(f\"    {metric.capitalize()}: {value:.4f}\")\n",
    "        print()\n",
    "\n",
    "    ## For ROUGE scores, each n-gram returns precision, recall, and f (f1) scores. \n",
    "    ## Rouge works on n-gram, so rouge-1 looks at single words (unigram), rouge-2 at two-word sequences (bigrams). Rouge-l looks at \n",
    "\n",
    "    # Next get BERTscore\n",
    "    P,R,F1 = score(summaries,content,lang='en')\n",
    "\n",
    "    # Print results\n",
    "    for i in range(len(summaries)):\n",
    "        print(f\"Summary {i+1}: Precision: {P[i].item()}, Recall: {R[i].item()}, F1: {F1[i].item()}\")\n",
    "\n",
    "eval_summaries(summaries,descriptions,orig_articles)\n",
    "eval_summaries(summaries,own_summ,orig_articles)\n",
    "\n",
    "# Function for averaging scores?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
